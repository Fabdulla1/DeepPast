"use strict";(self.webpackChunkdeeppast=self.webpackChunkdeeppast||[]).push([[9027],{7102:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"mainSideBar":[{"type":"link","label":"Intro","href":"/deeppast/challenge/intro","docId":"intro","unlisted":false},{"type":"link","label":"Deep Past Challenge","href":"/deeppast/challenge/overview","docId":"overview","unlisted":false},{"type":"category","label":"Data","items":[{"type":"link","label":"Akkadian Text","href":"/deeppast/challenge/data/akkadian","docId":"data/akkadian","unlisted":false},{"type":"link","label":"English Translation","href":"/deeppast/challenge/data/english","docId":"data/english","unlisted":false},{"type":"link","label":"Unicode Codepoints","href":"/deeppast/challenge/data/unicode","docId":"data/unicode","unlisted":false},{"type":"link","label":"Tablet Images / Segments","href":"/deeppast/challenge/data/images","docId":"data/images","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Tutorials","items":[{"type":"link","label":"Dataset Accessibility","href":"/deeppast/challenge/tutorials/dataset_accessibility","docId":"tutorials/dataset_accessibility","unlisted":false},{"type":"link","label":"SPARQL Queries","href":"/deeppast/challenge/tutorials/sparql_queries","docId":"tutorials/sparql_queries","unlisted":false},{"type":"link","label":"Dataset Conversion","href":"/deeppast/challenge/tutorials/dataset_conversion","docId":"tutorials/dataset_conversion","unlisted":false},{"type":"link","label":"Format Conversion Tools","href":"/deeppast/challenge/tutorials/format_conversion_tools","docId":"tutorials/format_conversion_tools","unlisted":false},{"type":"link","label":"Hugging Face Models","href":"/deeppast/challenge/tutorials/hugging_face_models","docId":"tutorials/hugging_face_models","unlisted":false},{"type":"link","label":"Text Annotation","href":"/deeppast/challenge/tutorials/text_annotation","docId":"tutorials/text_annotation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"FAQ","href":"/deeppast/challenge/faq","docId":"faq","unlisted":false},{"type":"link","label":"Discord","href":"https://discord.gg/XtCMyTrVCF"}]},"docs":{"data/akkadian":{"id":"data/akkadian","title":"Akkadian Text","description":"The OA corpus includes 13,000 digitized texts written in Old Assyrian Akkadian. These transliterations\u2014using Latin letters and diacritics\u2014represent the scholarly reading of cuneiform signs. Standard transliteration conventions (ORACC/CDLI/Leiden) are followed, with particular attention to preserving determinatives and line-level formatting.","sidebar":"mainSideBar"},"data/english":{"id":"data/english","title":"English Translation","description":"Where available, clause-level English translations accompany the Akkadian text. Sentence alignment is essential: participants will train models to learn mappings from Akkadian\u2019s Subject-Object-Verb (SOV) structure into English\u2019s Subject-Verb-Object (SVO). A good model learns from literal, word-for-word translations\u2014even if they differ from polished academic versions.","sidebar":"mainSideBar"},"data/images":{"id":"data/images","title":"Tablet Images / Segments","description":"High-resolution photographs of Old Assyrian tablets are available from CDLI, Yale\u2019s RTI collection, and other digitization efforts. The final and most complex challenge involves automatically segmenting these photos into individual signs or lines, preparing the data for image-to-text recognition models.","sidebar":"mainSideBar"},"data/unicode":{"id":"data/unicode","title":"Unicode Codepoints","description":"Each cuneiform sign corresponds to a Unicode character (range U+12000 to U+123FF). These codepoints will be used as ground truth for converting tablet images into structured scripts, and allow precise linking between signs, forms, and lexemes in Wikidata and ORACC.","sidebar":"mainSideBar"},"faq":{"id":"faq","title":"FAQ","description":"","sidebar":"mainSideBar"},"intro":{"id":"intro","title":"Intro","description":"The Deep Past Initiative (DPI) is launching a series of machine learning competitions to advance research in the world\u2019s oldest written languages. This first challenge focuses on Old Assyrian, a dialect of Akkadian used in the early second millennium BCE in the trading archives of merchants at Kanesh (K\xfcltepe, modern-day Turkey). While over 25,000 texts are known, fewer than half are translated\u2014making this a critical area for AI support.","sidebar":"mainSideBar"},"overview":{"id":"overview","title":"Deep Past Challenge","description":"\ud83e\udde9 Machine Translation: Akkadian Transliteration to English Translation (Text-to-Text)","sidebar":"mainSideBar"},"tutorials/dataset_accessibility":{"id":"tutorials/dataset_accessibility","title":"Dataset Accessibility","description":"Public datasets from CDLI, ORACC, ETCSL, eBL, and the OARE database form the backbone of this competition. Each provides open access to transliterations, metadata, and sometimes translations or images.","sidebar":"mainSideBar"},"tutorials/dataset_conversion":{"id":"tutorials/dataset_conversion","title":"Dataset Conversion","description":"Text normalization and format conversion tools are available to standardize data across ORACC, CDLI, and other repositories. Jupyter notebooks handle harmonization of spelling, determinatives, and line formatting conventions.","sidebar":"mainSideBar"},"tutorials/format_conversion_tools":{"id":"tutorials/format_conversion_tools","title":"Format Conversion Tools","description":"Custom Python notebooks convert between formats like ATF, JSON, CSV, and Unicode codepoints. This supports data preparation and downstream fine-tuning workflows.","sidebar":"mainSideBar"},"tutorials/hugging_face_models":{"id":"tutorials/hugging_face_models","title":"Hugging Face Models","description":"Participants can build on existing models hosted at huggingface.co/asahala and others created by the AWCA team, which include lemmatization, token classification, and machine translation for Akkadian and Sumerian.","sidebar":"mainSideBar"},"tutorials/sparql_queries":{"id":"tutorials/sparql_queries","title":"SPARQL Queries","description":"Wikidata and FactGrid provide structured linguistic data. Participants can explore Akkadian and Sumerian lexemes, senses, and sign variants via SPARQL queries to retrieve rich, multilingual annotations.","sidebar":"mainSideBar"},"tutorials/text_annotation":{"id":"tutorials/text_annotation","title":"Text Annotation","description":"Future challenges will require annotation of sign boundaries, POS-tags, and named entities. Current tools allow manual and semi-automated annotation to align linguistic labels with raw transliterations and sign sequences.","sidebar":"mainSideBar"}}}}')}}]);